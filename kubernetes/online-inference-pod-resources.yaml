apiVersion: v1
kind: Pod
metadata:
  name: online-inference-pod
spec:
  containers:
  - name: online-inference
    image: yessen3103/online_inference
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "256Mi"
        cpu: "1000m"
      limits:
        memory: "512Mi"
        cpu: "2000m"
